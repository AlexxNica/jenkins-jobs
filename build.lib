#!/bin/sh
# This shell script library sets variables and supplies functions shared
# between continuous integration build scripts.  It is intended to be
# loaded, e.g.,  by scripts that are run by the Jenkins CI server.  The
# working directory is assumed to be the root of a workspace where the
# website code is checked out into a subdirectory.

# Paths:
: ${WORKSPACE_ROOT:=.}
: ${REPOS_ROOT:=/var/lib/jenkins/repositories}   # where the git repos live

# Make this path absolute, so clients can chdir with impunity.  We use
# the nice side-effect of readlink -f that it absolutizes.
WORKSPACE_ROOT=`readlink -f "$WORKSPACE_ROOT"`

# Default Slack channel to use for alerting:
: ${SLACK_CHANNEL:=#bot-testing}


# Sanity check that we're in the right place, the working directory
# above the website source directory.  This is hard to do in general
# -- the make-check-worker workspace, in particular, doesn't look like
# any of the others -- so we try to catch the most common error, that
# we're inside some git repo or another.
(
    cd "$WORKSPACE_ROOT"
    if git rev-parse 2>/dev/null; then
        echo "$WORKSPACE_ROOT is a git repo, not the workspace dir"
        exit 1
    fi
)

# Send an alert to Slack and the logs.  You must have secrets decrypted.
# The alertlib subrepo in webapp must be checked out for this to work.
# $1: severity level
# $2+: message
# If $DEPLOYER_USERNAME is set, then that is prepended to the alert message.
_alert() {
    severity="$1"
    shift
    if echo "$@" | grep -q '<[^ ].*>'; then    # a hack, but a pretty good one
       html=--html
    else
       html=
    fi
    if [ -n "$DEPLOYER_USERNAME" ]; then
        msg="$DEPLOYER_USERNAME: $@"
    else
        msg="$@"
    fi
    echo "$msg" \
        | "$WORKSPACE_ROOT"/jenkins-tools/alertlib/alert.py \
              --severity="$severity" $html \
              --slack "$SLACK_CHANNEL" --logs
}


# The filename to use as a lock in order to serialize fetches.
# TODO(csilvers): have there be a lock per repo, rather than one
# global lock.  This is tricky with submodules, where you can both
# fetch in them directly and indirectly via a 'git submodule update'.
_flock_file() {
    echo "$REPOS_ROOT/flock.fetch"
}

# Call this from within the repo that you want to do the fetching.
_safe_fetch() {
    # We use flock to protect against two clients trying to fetch in
    # the same dir at the same time.  This is because different
    # clients will both, in the end, be fetching into $REPOS_ROOT.
    flock -w 7230 "`_flock_file`" timeout 120m git fetch --prune --tags --progress origin
}

# Call this from within the repo that you want to do the fetching.
# You must do this *after* you've checked out the commit you want
# to be at (which is why we can't have a separate fetch step here).
# This pulls bigfiles in both the main repo and all subrepos.
# $1+ (optional): specific files to pull
_safe_pull_bigfiles() {
    # 'bigfile pull' stores the objects in a shared dir in
    # $REPOS_ROOT, so we need the lock for this.
    ( flock 9        # use fd 9 for locking (see the end of this paren)
      # First, clear up some space if need be by getting rid of old bigfiles.
      find "$REPOS_ROOT" -path '*/.git*/bigfile' -type d | while read bfdir; do
          timeout 120m find "$bfdir/objects" -mtime +2 -type f -print0 \
              | xargs -r0 rm -f
      done
      export PATH="$HOME/git-bigfile/bin:$PATH"
      # I don't know if this is still needed, but it seems to be
      # necessary for boto, used by git-bigfiles.
      export PYTHONPATH="/usr/lib/python2.7/dist-packages:$PYTHONPATH"
      timeout 120m git bigfile pull "$@"
      timeout 120m git submodule foreach git bigfile pull "$@"
    ) 9>"`_flock_file`"
}

# $1: the branch we're in.  We assume this branch also exists on the remote.
_safe_rebase() {
    timeout 10m git rebase "origin/$1" || {
        timeout 10m git rebase --abort
        exit 1
    }
}

# $1: the commit-ish to check out to.
# NOTE: this does a bunch of 'git reset --hard's.  Do not call this
# if you have stuff you want to commit.
_safe_destructive_checkout() {
    # Perhaps 'git checkout -f "$1"' would work just as well, but I'm paranoid.
   if [ -n "`git status --porcelain | head -n 1`" ]; then
        timeout 10m git reset --hard
        timeout 10m git submodule foreach --recursive git reset --hard
        timeout 10m git clean -ffd
        timeout 10m git submodule foreach --recursive git clean -ffd
    fi

   if ! timeout 10m git checkout "$1" -- ; then
       _alert error "'$1' is not a valid git revision"
       exit 1
   fi

   if [ -n "`git status --porcelain | head -n 1`" ]; then
        timeout 10m git reset --hard
        timeout 10m git submodule foreach --recursive git reset --hard
        timeout 10m git clean -ffd
        timeout 10m git submodule foreach --recursive git clean -ffd
    fi

    # We could also do _safe_pull_bigfiles here to fetch any new
    # bigfiles from the server, but since it's slow we just punt and
    # make clients call it directly if interested.
}

# $* (optional): submodules to update.  If left out, update all submodules.
#    If the string 'no_submodules', update no submodules.  Can be a
#    directory, in which case we update all submodules under that dir.
# NOTE: This calls 'git clean' so be careful if you expect edits in the repo.
_safe_update_submodules() {
    if [ "$*" = "no_submodules" ]; then
        return
    fi
    # If we ourselves are a submodule, we don't have any submodules to update.
    if git rev-parse --git-dir | fgrep -q .git/modules; then
        return
    fi

    # It's not really safe to call git new-workdir on each submodule,
    # since it doesn't deal well with submodules appearing and
    # disappearing between branches.  So we hard-code a few of the big
    # submodules that have been around a long time and aren't going
    # anywhere, and use git new-workdir on those, and use 'normal'
    # submodules for everything else.
    new_workdir_repos=""
    normal_repos="$*"
    if [ -z "$normal_repos" ]; then        # means 'all the repos'
        normal_repos="`git submodule status | awk '{print $2}'`"
    fi

    if echo "$normal_repos" | grep -e intl -e intl/translations; then
       new_workdir_repos="intl/translations $new_workdir_repos"
       normal_repos="`echo $normal_repos | tr " " "\012" | grep -v intl`"
    fi
    if echo "$normal_repos" | grep -e khan-exercises; then
       new_workdir_repos="khan-exercises $new_workdir_repos"
       normal_repos="`echo $normal_repos | tr " " "\012" | grep -v khan-exercises`"
    fi

    # Handle the repos we (possibly) need to make workdirs for.
    if [ -n "$new_workdir_repos" ]; then
        repo_dir="`pwd`"
        ( flock 9        # use fd 9 for locking (see the end of this paren)
          # Get to the shared repo (inside $REPOS_ROOT).  We follow the
          # existing symlinks inside main_repo/.git/ to get there.
          cd `readlink -f .git/config | xargs -n1 dirname | xargs -n1 dirname`

          timeout 10m git submodule sync --recursive
          timeout 60m git submodule update --init --recursive -- $new_workdir_repos
          for path in $new_workdir_repos; do
              [ -f "$repo_dir/$path/.git" ] || git new-workdir "`pwd`/$path" "$repo_dir/$path"
          done
        ) 9>"`_flock_file`"
    fi

    # Now update the 'normal' repos.
    if [ -n "$normal_repos" ]; then
        timeout 10m git submodule sync --recursive
        timeout 60m git submodule update --init --recursive -- $normal_repos
    fi

    # Finally, we need to fix the submodule HEADs in the workdir.
    timeout 10m git submodule update -- "$@"
}

# checks out the given commit-ish, fetching (or cloning) first.
# The repo is always checked out under $WORKSPACE_ROOT and there
# is no way to specially set the directory name.
# $1: repo to clone
# $2: commit-ish to check out at.  If necessary, does a pull from
#     origin first.
# $3+ (optional): submodules to update to that commit as well.  If
#     left out, update all submodules.  If the string 'no_submodules',
#     update no submodules.
safe_sync_to() {
    repo="$1"
    shift
    commit="$1"
    shift
    (
    repo_workspace="$WORKSPACE_ROOT/`basename "$repo"`"
    if [ -d "$repo_workspace" ]; then
        cd "$repo_workspace"
        _safe_fetch
        _safe_destructive_checkout "$commit"
    else
        # The git objects/etc live under REPOS_ROOT (all workspaces
        # share the same objects).
        repo_dir="$REPOS_ROOT/`basename "$repo"`"
        # Clone or update into repo-dir, the canonical home.
        if [ -d "$repo_dir" ]; then
            ( cd "$repo_dir" && _safe_fetch )
        else
            timeout 60m git clone "$repo" "$repo_dir"
        fi
        # Now create our workspace!
        timeout 10m git new-workdir "$repo_dir" "$repo_workspace" "$commit"
        cd "$repo_workspace"
    fi

    # Merge from origin if need be.
    if timeout 10m git ls-remote --exit-code . origin/"$commit"; then
        _safe_rebase "$commit"
    fi

    _safe_update_submodules "$@"

    # We could also do _safe_pull_bigfiles here to fetch any new
    # bigfiles from the server, but since it's slow we just punt and
    # make clients call it directly if interested.
    )
}

# Like safe_sync_to, but if the commit-ish exists on origin -- e.g.
# it's a branch that's been pushed to github -- sync to origin/commit
# and set commit to be that.  This is useful when we only care about
# what exists on github, because no local changes are expected.
# $1: repo to clone
# $2: commit-ish to check out at.  If origin/commit-ish exists,
#     sync to that instead of commit-ish.  (This is usually true,
#     especially when commit-ish is a branch name.)
# $3+ (optional): submodules to update to that commit as well.  If
#     left out, update all submodules.  If the string 'no_submodules',
#     update no submodules.
safe_sync_to_origin() {
    repo="$1"
    shift
    commit="$1"
    shift

    repo_workspace="$WORKSPACE_ROOT/`basename "$repo"`"
    if timeout 10m \
       git ls-remote --exit-code "$repo_workspace" origin/"$commit"; then
        orig_commit="$commit"    # safe_sync_to overwrites '$commit', ugh
        safe_sync_to "$repo" "origin/$commit" "$@"
        # Make it so our local branch matches what's on origin
        (
            cd "$repo_workspace"
            git branch -f "$orig_commit" origin/"$orig_commit"
            git checkout "$orig_commit"
        )
    else
        safe_sync_to "$repo" "$commit" "$@"
    fi
}

# $1: directory to run the pull in (can be in a sub-repo)
# $2: branch to pull
# $3+ (optional): submodules to pull as well.  If left out, update all
#     submodules.  If the string 'no_submodules', update no submodules.
# NOTE: this does a git reset, and always changes the branch to master!
# It also always inits and updates listed subrepos.
safe_pull_in_branch() {
    (
    cd "$1"
    shift
    branch="$1"
    shift
    _safe_destructive_checkout "$branch"
    _safe_fetch
    _safe_rebase "$branch"
    _safe_update_submodules "$@"
    # We could also do _safe_pull_bigfiles here to fetch any new
    # bigfiles from the server, but since it's slow we just punt and
    # make clients call it directly if interested.
    )
}

# Does a safe_pull after switching to the 'master' branch.
# $1: directory to run the pull in (can be in a sub-repo)
safe_pull() {
    dir="$1"
    shift
    safe_pull_in_branch "$dir" "master" "$@"
}

# $1: directory to run the push in (can be in a sub-repo)
safe_push() {
    (
    cd "$1"
    branch=`git rev-parse --symbolic-full-name HEAD | sed 's,^.*/,,'`
    # In case there have been any changes since the script began, we
    # do 'pull; push'.  On failure, we undo all our work.
    _safe_fetch
    _safe_rebase "$branch" || {
        timeout 10m git reset --hard HEAD^
        exit 1
    }
    # If this repo uses bigfiles, we have to push them to S3 now, as well.
    timeout 60m env PATH="$HOME/git-bigfile/bin:$PATH" \
                    PYTHONPATH="/usr/lib/python2.7/dist-packages:$PYTHONPATH" \
                    git bigfile push
    # Cleanup bigfile objects older than two days, both in the main
    # module and in submodules
    find "$REPOS_ROOT" -path '*/.git*/bigfile' -type d | while read bfdir; do
        timeout 120m find "$bfdir/objects" -mtime +2 -type f -print0 \
            | xargs -r0 rm -f
    done

    # Ensure we push using SSH to use Jenkins' configured SSH keys.
    ssh_origin=`git config --get remote.origin.url | sed 's,^https://github.com/,git@github.com:,'`
    timeout 60m git push "$ssh_origin" "$branch" || {
        timeout 10m git reset --hard HEAD^
        exit 1
    }
    )
}

# This updates our repo to point to the current master of the given subrepo.
# $1: the directory of the submodule
safe_update_submodule_pointer_to_master() {
    dir="$1"
    shift
    branch=`git rev-parse --symbolic-full-name HEAD | sed 's,^.*/,,'`
    safe_pull_in_branch . "$branch"
    ( cd "$dir" && timeout 10m git checkout master )
    timeout 10m git add "$dir"
    if git commit --dry-run | grep -q -e 'no changes added' -e 'nothing to commit' -e 'nothing added'; then
        echo "No need to update substate for $dir: no new content created"
    else
        timeout 10m git commit -m "$dir substate [auto]"
        safe_push .
    fi
}


# $1: the directory to commit in (can be in a sub-repo)
# $2+: arguments to 'git commit' (we add '-a' automatically)
# If "$1" is a sub-repo, this function *must* be called from within
# the main repo that includes the sub-repo.
# NOTE: This 'git add's all new files in the commit-directory.
safe_commit_and_push() {
    dir="$1"
    shift
    (
    cd "$dir"
    if [ -z "`git status --porcelain | head -n 1`" ]; then
        echo "No changes, skipping commit"
    else
        timeout 10m git add .
        timeout 10m git commit -a "$@"
    fi
    )
    safe_push "$dir"
}

# $1: the directory of the main repository
# $2: the directory of the submodule relative to "$1"
# $3+: arguments to 'git commit' (we add '-a' automatically)
# NOTE: This 'git add's all new files in the commit-directory ($2).
safe_commit_and_push_submodule() {
    repo_dir=$1
    shift
    submodule_dir=$1
    shift
    safe_commit_and_push "$repo_dir/$submodule_dir" "$@"

    (
        cd "$repo_dir"
        safe_update_submodule_pointer_to_master "$submodule_dir"
    )
}


# Checks out a branch and merges another branch into it
# $1: the directory to run the merge in
# $2: the commit-ish (branch or sha1) into which to merge the other branch.
#     If it's a sha1, it must be a superset of "branch".  We check out $2
#     in the working dir $1 in order to do the merge.  Cannot be master.
# $3: the branch to merge into $2.  Must be a branch name, not a sha1.
# $4+ (optional): submodules to update after the merge.  If left out, update
#     all submodules.  If the string 'no_submodules', update no submodules.
# TODO(benkraft): wrap this whole assembly in failure-handling, so that if
# something unexpected fails, at least it doesn't fail silently.
safe_merge_from_branch() {
    dir="$1"
    shift
    git_revision="$1"
    shift
    merge_from="$1"
    shift
    (
    cd "$dir"
    if [ "$git_revision" = "master" ] ; then
        _alert error "You must deploy from a branch, you can't deploy from master"
        exit 1
    fi

    # Make sure our local merge_from matches the remote
    git fetch origin +"refs/heads/$merge_from:refs/remotes/origin/$merge_from"
    git checkout "$merge_from"
    git reset --hard "origin/$merge_from"

    # Set our local branch to be the same as the origin branch.  This
    # is needed in cases when a previous deploy set the local (jenkins)
    # branch to commit X, but subsequent commits have moved the remote
    # (github) version of the branch to commit Y.  This also moves us
    # from a (potentially) detached-head state to a head-at-branch state.
    # Finally, it makes sure the ref exists locally, so we can do
    # 'git rev-parse branch' rather than 'git rev-parse origin/branch'
    # (though only if we're given a branch rather than a commit as $2).
    if git ls-remote --exit-code . "origin/$git_revision" ; then
        git fetch origin "+refs/heads/$git_revision:refs/remotes/origin/$git_revision"
        # The '--' is needed if git_revision is both a branch and
        # directory, e.g. 'sat'.  '--' says 'treat it as a branch'.
        git checkout "$git_revision" --
        git reset --hard "origin/$git_revision"
    else
        if ! git checkout "$git_revision" -- ; then
            _alert error "'$git_revision' is not a valid git revision"
            exit 1
        fi
    fi

    head_commit="`git rev-parse HEAD`"
    merge_from_commit="`git rev-parse "$merge_from"`"

    # Sanity check: HEAD should be at the revision we want to deploy from.
    if [ "$head_commit" != "`git rev-parse "$git_revision"`" ] ; then
        _alert error "HEAD unexpectedly at '$head_commit', not '$git_revision'"
        exit 1
    fi

    # If the current commit is a super-set of merge_from, we're done, yay!
    base="`git merge-base "$git_revision" "$merge_from_commit"`"
    if [ "$base" = "$merge_from_commit" ] ; then
        echo "$git_revision is a superset of $merge_from, no need to merge"
        exit 0
    fi

    # Now we need to merge merge_from into our branch.  First, make sure
    # we *are* a branch.  git show-ref returns line like 'd41eba92 refs/...'
    if ! git show-ref | cut -d ' ' -f 2 | grep -q "^refs/remotes/origin/$git_revision$" ; then
        _alert error "$git_revision is not a branch name on the remote"
        exit 1
    fi

    # The merge exits with rc > 0 if there were conflicts
    echo "Merging $merge_from into $git_revision"
    if ! git merge "$merge_from" ; then
        git merge --abort
        _alert error "Merge conflict: must merge $merge_from into $git_revision manually."
        exit 1
    fi

    # There's a race condition if someone commits to this branch while
    # this script is running, so check for that.
    if ! git push origin "$git_revision" ; then
        git reset --hard "$head_commit"
        _alert error "Someone committed to $git_revision while we've been deploying!"
        exit 1
    fi

    _safe_update_submodules "$@"

    echo "Done merging $merge_from into $git_revision"
    )
}

# Checks out a branch and merges master into it
safe_merge_from_master() {
    dir="$1"
    shift
    git_revision="$1"
    shift
    safe_merge_from_branch "$dir" "$git_revision" "master" "$@"
}


# Typically, you'll source this file into your own shell script
# (`. build.lib`) to have access to its functions, but you can
# also call it from the commandline, in which case you can run
# any function here with args (typically a safe_* git function).
if [ -n "$1" ]; then
    set -ex
   "$@"
fi
